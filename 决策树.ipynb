{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字典特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  60.]\n",
      " [  0.   0.   1.  30.]]\n",
      "['city=上海', 'city=北京', 'city=深圳', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "datas=[{'city': '北京','temperature':100},\n",
    "{'city': '上海','temperature':60},\n",
    "{'city': '深圳','temperature':30}]\n",
    "\n",
    "transfer =DictVectorizer(sparse=False)#是否返回稀疏矩阵\n",
    "# transfer =DictVectorizer(sparse=True)\n",
    "#字典特征提取,one-hot编码\n",
    "new_datas =transfer.fit_transform(datas)\n",
    "print(new_datas)\n",
    "#获取每个特征的名称\n",
    "print(transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本提取\n",
    "- 对文本进行特征值化,统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #主要处理英文,对中文不友好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 1 1 0]\n",
      " [1 1 0 1 0 1 1 0 1]\n",
      " [0 1 1 1 1 0 0 1 0]]\n",
      "['dislike', 'is', 'java', 'life', 'like', 'long', 'python', 'short', 'too']\n"
     ]
    }
   ],
   "source": [
    "text=[\"life is short,i like python\",\n",
    "\"life is too long,i dislike python\",\n",
    "     \"life is short,i like Java\"]\n",
    "\n",
    "transfer =CountVectorizer()\n",
    "\n",
    "#文本特征提取\n",
    "new_data1 = transfer.fit_transform(text)\n",
    "# print(new_data1)#稀疏矩阵\n",
    "print(new_data1.toarray())\n",
    "print(transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "['0时梯度为0', 'rate', 'relu函数在训练的时候', '一不小心有可能导致梯度为零', '不再对任何数据有所响应', '如果开始设置了一个合适的较小的learning', '如果设置的learning', '实际操作中', '比较大', '由于relu在x', '这个relu神经元坏死了', '这个神经元有可能再也不会被任何数据激活', '这个问题发生的情况其实也不会太频繁', '这样就导致负的梯度在这个relu被置零', '那么很有可能网络中的大量的神经元都坏死了']\n"
     ]
    }
   ],
   "source": [
    "text=[\"ReLU函数在训练的时候，一不小心有可能导致梯度为零。由于ReLU在x<0时梯度为0，这样就导致负的梯度在这个ReLU被置零，这个神经元有可能再也不会被任何数据激活，这个ReLU神经元坏死了，不再对任何数据有所响应。实际操作中，如果设置的learning rate 比较大，那么很有可能网络中的大量的神经元都坏死了。如果开始设置了一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁。\"]\n",
    "\n",
    "transfer =CountVectorizer()\n",
    "\n",
    "#文本特征提取\n",
    "new_data1 = transfer.fit_transform(text)\n",
    "# print(new_data1)#稀疏矩阵\n",
    "print(new_data1.toarray())\n",
    "print(transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。', '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。', '如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。']\n",
      "文本特征抽取的结果：\n",
      " [[0.         0.         0.         0.43643578 0.         0.\n",
      "  0.         0.         0.         0.21821789 0.         0.21821789\n",
      "  0.         0.         0.         0.         0.21821789 0.21821789\n",
      "  0.         0.43643578 0.         0.21821789 0.         0.43643578\n",
      "  0.21821789 0.         0.         0.         0.21821789 0.21821789\n",
      "  0.         0.         0.21821789 0.        ]\n",
      " [0.2410822  0.         0.         0.         0.2410822  0.2410822\n",
      "  0.2410822  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.2410822  0.55004769 0.         0.\n",
      "  0.         0.         0.2410822  0.         0.         0.\n",
      "  0.         0.48216441 0.         0.         0.         0.\n",
      "  0.         0.2410822  0.         0.2410822 ]\n",
      " [0.         0.644003   0.48300225 0.         0.         0.\n",
      "  0.         0.16100075 0.16100075 0.         0.16100075 0.\n",
      "  0.16100075 0.16100075 0.         0.12244522 0.         0.\n",
      "  0.16100075 0.         0.         0.         0.16100075 0.\n",
      "  0.         0.         0.3220015  0.16100075 0.         0.\n",
      "  0.16100075 0.         0.         0.        ]]\n",
      "返回特征名字：\n",
      " ['之前', '了解', '事物', '今天', '光是在', '几百万年', '发出', '取决于', '只用', '后天', '含义', '大部分', '如何', '如果', '宇宙', '我们', '所以', '放弃', '方式', '明天', '星系', '晚上', '某样', '残酷', '每个', '看到', '真正', '秘密', '绝对', '美好', '联系', '过去', '还是', '这样']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba\n",
    "\n",
    "def cut_word(text):\n",
    "    \"\"\"\n",
    "    对中文进行分词\n",
    "    \"我爱北京天安门\"————>\"我 爱 北京 天安门\"\n",
    "    :param text:\n",
    "    :return: text\n",
    "    \"\"\"\n",
    "    # 用结巴对中文字符串进行分词\n",
    "    text = \" \".join(list(jieba.cut(text)))\n",
    "\n",
    "    return text\n",
    "\n",
    "def text_chinese_tfidf_demo():\n",
    "    \"\"\"\n",
    "    对中文进行特征抽取\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = [\"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "            \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "            \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"]\n",
    "    # 将原始数据转换成分好词的形式\n",
    "    text_list = []\n",
    "    for sent in data:\n",
    "        text_list.append(cut_word(sent))\n",
    "    print(text_list)\n",
    "#     data =cut_word(data)\n",
    "#     print(data)\n",
    "    \n",
    "    # 1、实例化一个转换器类\n",
    "    # transfer = CountVectorizer(sparse=False)\n",
    "    transfer = TfidfVectorizer(stop_words=['一种', '不会', '不要'])\n",
    "    # 2、调用fit_transform\n",
    "    data = transfer.fit_transform(text_list)\n",
    "    print(\"文本特征抽取的结果：\\n\", data.toarray())\n",
    "    print(\"返回特征名字：\\n\", transfer.get_feature_names())\n",
    "\n",
    "    return None\n",
    "text_chinese_tfidf_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
